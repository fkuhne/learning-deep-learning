{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9cc808",
   "metadata": {},
   "source": [
    "# Deep Learning Example - Iris \n",
    "\n",
    "This examples demonstrates the core deep learning model building concepts using the Keras library. The Iris flower dataset is used to build the model and perform classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141cfab",
   "metadata": {},
   "source": [
    "### 5.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17aae7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (66.0.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "     ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/8.3 MB 1.7 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.3/8.3 MB 2.9 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.0/8.3 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 2.3/8.3 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 5.3/8.3 MB 22.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 5.5/8.3 MB 19.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 6.3/8.3 MB 19.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 6.7/8.3 MB 19.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 7.4/8.3 MB 17.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 7.7/8.3 MB 17.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 8.1/8.3 MB 15.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.3/8.3 MB 16.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.3/8.3 MB 14.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ---------------------------------------- 0.0/298.0 kB ? eta -:--:--\n",
      "     ------------------------------------- 298.0/298.0 kB 19.2 MB/s eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kuhnef\\appdata\\local\\anaconda3\\envs\\deeplearning-linkedin\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Install related libraries for the course. \n",
    "#This is a common requirement for all other exampels too\n",
    "\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fabf059",
   "metadata": {},
   "source": [
    "### 4.2. Prepare Input Data for Deep Learning\n",
    "\n",
    "Perform the following steps for preparing data\n",
    "\n",
    "1. Load data into a pandas dataframe\n",
    "2. Convert the dataframe to a numpy array\n",
    "3. Scale the feature dataset\n",
    "4. Use one-hot-encoding for the target variable\n",
    "5. Split into training and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db4bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Data :\n",
      "------------------------------------\n",
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Features before scaling :\n",
      "------------------------------------\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "\n",
      "Target before scaling :\n",
      "------------------------------------\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Features after scaling :\n",
      "------------------------------------\n",
      "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n",
      "\n",
      "Target after one-hot-encoding :\n",
      "------------------------------------\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "Train Test Dimensions:\n",
      "------------------------------------\n",
      "(135, 4) (135, 3) (15, 4) (15, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Load Data and review content\n",
    "iris_data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
    "print(iris_data.head())\n",
    "\n",
    "#Use a Label encoder to convert String to numeric values \n",
    "#for the target variable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris_data['Species'] = label_encoder.fit_transform(\n",
    "                                iris_data['Species'])\n",
    "\n",
    "#Convert input to numpy array\n",
    "np_iris = iris_data.to_numpy()\n",
    "\n",
    "#Separate feature and target variables\n",
    "X_data = np_iris[:,0:4]\n",
    "Y_data=np_iris[:,4]\n",
    "\n",
    "print(\"\\nFeatures before scaling :\\n------------------------------------\")\n",
    "print(X_data[:5,:])\n",
    "print(\"\\nTarget before scaling :\\n------------------------------------\")\n",
    "print(Y_data[:5])\n",
    "\n",
    "#Create a scaler model that is fit on the input data.\n",
    "scaler = StandardScaler().fit(X_data)\n",
    "\n",
    "#Scale the numeric feature variables\n",
    "X_data = scaler.transform(X_data)\n",
    "\n",
    "#Convert target variable as a one-hot-encoding array\n",
    "Y_data = tf.keras.utils.to_categorical(Y_data,3)\n",
    "\n",
    "print(\"\\nFeatures after scaling :\\n------------------------------------\")\n",
    "print(X_data[:5,:])\n",
    "print(\"\\nTarget after one-hot-encoding :\\n------------------------------------\")\n",
    "print(Y_data[:5,:])\n",
    "\n",
    "#Split training and test data\n",
    "X_train,X_test,Y_train,Y_test = train_test_split( X_data, Y_data, test_size=0.10)\n",
    "\n",
    "print(\"\\nTrain Test Dimensions:\\n------------------------------------\")\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5fad2",
   "metadata": {},
   "source": [
    "### 4.3. Creating a Model\n",
    "\n",
    "Creating a model in Keras requires defining the following\n",
    "\n",
    "1. Number of hidden layers\n",
    "2. Number of nodes in each layer\n",
    "3. Activation functions\n",
    "4. Loss Function & Accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a0be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden-Layer-1 (Dense)      (None, 128)               640       \n",
      "                                                                 \n",
      " Hidden-Layer-2 (Dense)      (None, 128)               16512     \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,539\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "#Number of classes in the target variable\n",
    "NB_CLASSES=3\n",
    "\n",
    "#Create a sequencial model in Keras\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Add the first hidden layer\n",
    "model.add(keras.layers.Dense(128,                    #Number of nodes\n",
    "                             input_shape=(4,),       #Number of input variables\n",
    "                              name='Hidden-Layer-1', #Logical name\n",
    "                              activation='relu'))    #activation function\n",
    "\n",
    "#Add a second hidden layer\n",
    "model.add(keras.layers.Dense(128,\n",
    "                              name='Hidden-Layer-2',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add an output layer with softmax activation\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                             name='Output-Layer',\n",
    "                             activation='softmax'))\n",
    "\n",
    "#Compile the model with loss & metrics\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Print the model meta-data\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6677e",
   "metadata": {},
   "source": [
    "### 4.4. Training and evaluating the Model\n",
    "\n",
    "Training the model involves defining various training models and then perform \n",
    "forward and back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make it verbose so we can see the progress\n",
    "VERBOSE=1\n",
    "\n",
    "#Setup Hyper Parameters for training\n",
    "\n",
    "#Set Batch size\n",
    "BATCH_SIZE=16\n",
    "#Set number of epochs\n",
    "EPOCHS=10\n",
    "#Set validation split. 20% of the training data will be used for validation\n",
    "#after each epoch\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
    "\n",
    "#Fit the model. This will perform the entire training cycle, including\n",
    "#forward propagation, loss computation, backward propagation and gradient descent.\n",
    "#Execute for the specified batch sizes and epoch\n",
    "#Perform validation after each epoch \n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "print(\"\\nAccuracy during Training :\\n------------------------------------\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot accuracy of the model after each epoch.\n",
    "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
    "plt.title(\"Accuracy improvements with Epoch\")\n",
    "plt.show()\n",
    "\n",
    "#Evaluate the model against the test dataset and print results\n",
    "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efdff7",
   "metadata": {},
   "source": [
    "### 4.5. Saving and Loading Models\n",
    "\n",
    "The training and inference environments are usually separate. Models need to be saved after they are validated. They are then loaded into the inference environments for actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a model\n",
    "    \n",
    "model.save(\"iris_save\")\n",
    "    \n",
    "#Loading a Model \n",
    "loaded_model = keras.models.load_model(\"iris_save\")\n",
    "\n",
    "#Print Model Summary\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc6fb5",
   "metadata": {},
   "source": [
    "### 4.6. Predictions with Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58037d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw prediction data\n",
    "prediction_input = [[6.6, 3. , 4.4, 1.4]]\n",
    "\n",
    "#Scale prediction data with the same scaling model\n",
    "scaled_input = scaler.transform(prediction_input)\n",
    "\n",
    "#Get raw prediction probabilities\n",
    "raw_prediction = model.predict(scaled_input)\n",
    "print(\"Raw Prediction Output (Probabilities) :\" , raw_prediction)\n",
    "\n",
    "#Find prediction\n",
    "prediction = np.argmax(raw_prediction)\n",
    "print(\"Prediction is \", label_encoder.inverse_transform([prediction]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76d3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
